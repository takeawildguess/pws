<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>take a wild guess</title>
    <link>https://takeawildguess.net/</link>
    <description>Recent content on take a wild guess</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 24 Feb 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://takeawildguess.net/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Publications</title>
      <link>https://takeawildguess.net/about/about_publications/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://takeawildguess.net/about/about_publications/</guid>
      <description>Here I list my main publications during my PhD and post-doc research.</description>
    </item>
    
    <item>
      <title>Project 1</title>
      <link>https://takeawildguess.net/project/project1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://takeawildguess.net/project/project1/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Talks</title>
      <link>https://takeawildguess.net/about/about_talks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://takeawildguess.net/about/about_talks/</guid>
      <description>Here I list my main talks at the Machine-Learning meetup in Torino, Italy.</description>
    </item>
    
    <item>
      <title>Project 2</title>
      <link>https://takeawildguess.net/project/project2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://takeawildguess.net/project/project2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Experience and education</title>
      <link>https://takeawildguess.net/about/about_workeducation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://takeawildguess.net/about/about_workeducation/</guid>
      <description>ciao me.</description>
    </item>
    
    <item>
      <title>Project 3</title>
      <link>https://takeawildguess.net/project/project3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://takeawildguess.net/project/project3/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Project 4</title>
      <link>https://takeawildguess.net/project/project4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://takeawildguess.net/project/project4/</guid>
      <description></description>
    </item>
    
    <item>
      <title>How to learn to classify - Part 4</title>
      <link>https://takeawildguess.net/blog/logisticregression_part4/</link>
      <pubDate>Sun, 24 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://takeawildguess.net/blog/logisticregression_part4/</guid>
      <description>1. Introduction and assumptions In this post-series, we are going to study the very basic modeling for classification problems, the logistic regression. Classification entails that the output is a discrete variable taking values on a pre-defined limited set, where the set dimension is the number of classes. Some examples are spam detection, object recognition and topic identification.
We focus on the input/output space, the predictor structure, the learning algorithm and on applying the method to different datasets.</description>
    </item>
    
    <item>
      <title>How to learn to classify - Part 3</title>
      <link>https://takeawildguess.net/blog/logisticregression_part3/</link>
      <pubDate>Sun, 17 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://takeawildguess.net/blog/logisticregression_part3/</guid>
      <description>1. Introduction and assumptions In this post-series, we are going to study the very basic modeling for classification problems, the logistic regression. Classification entails that the output is a discrete variable taking values on a pre-defined limited set, where the set dimension is the number of classes. Some examples are spam detection, object recognition and topic identification.
We focus on the input/output space, the predictor structure, the learning algorithm and on applying the method to different datasets.</description>
    </item>
    
    <item>
      <title>How to learn to classify - Part 2</title>
      <link>https://takeawildguess.net/blog/logisticregression_part2/</link>
      <pubDate>Sun, 10 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://takeawildguess.net/blog/logisticregression_part2/</guid>
      <description>1. Introduction and assumptions In this post-series, we are going to study the very basic modeling for classification problems, the logistic regression. Classification entails that the output is a discrete variable taking values on a pre-defined limited set, where the set dimension is the number of classes. Some examples are spam detection, object recognition and topic identification.
We focus on the input/output space, the predictor structure, the learning algorithm and on applying the method to different datasets.</description>
    </item>
    
    <item>
      <title>How to learn to classify - Part 1</title>
      <link>https://takeawildguess.net/blog/logisticregression_part1/</link>
      <pubDate>Sun, 03 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://takeawildguess.net/blog/logisticregression_part1/</guid>
      <description>1. Problem formulation We want to create a simplified representation (model) of real/world from available data. The model architecture can be seen as a box that takes some quantities as input, performs some internal computation and returns some other quantities as output. The inputs are also referred to as features or predictors of the problem to solve, since they contain valuable information that the model should exploit to come up with the correct outcome.</description>
    </item>
    
    <item>
      <title>Hello world example for Machine learning - Part 4</title>
      <link>https://takeawildguess.net/blog/linreg/linreg4/</link>
      <pubDate>Sun, 27 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://takeawildguess.net/blog/linreg/linreg4/</guid>
      <description>1. Introduction We have introduced the concept of the linear-regression problem and the structure to solve it in a &amp;ldquo;machine-learning&amp;rdquo; fashion in this post, while we have applied the theory to a simple but practical case of linear-behavior identification from a bunch of data that are generated in a synthetic way here and extend the analysis to a multi-linear case where more than one feature (or input) are fed to the model to predict the outcome here.</description>
    </item>
    
    <item>
      <title>Hello world example for Machine learning - Part 5</title>
      <link>https://takeawildguess.net/blog/linreg/linreg5/</link>
      <pubDate>Sun, 27 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://takeawildguess.net/blog/linreg/linreg5/</guid>
      <description>1. Introduction We have introduced the concept of the linear-regression problem and the structure to solve it in a &amp;ldquo;machine-learning&amp;rdquo; fashion in this post, while we have applied the theory to a simple but practical case of linear-behavior identification from a bunch of data that are generated in a synthetic way here and extend the analysis to a multi-linear case where more than one feature (or input) are fed to the model to predict the outcome here.</description>
    </item>
    
    <item>
      <title>Hello world example for Machine learning - Part 3</title>
      <link>https://takeawildguess.net/blog/linreg/linreg3/</link>
      <pubDate>Sun, 20 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://takeawildguess.net/blog/linreg/linreg3/</guid>
      <description>1. Introduction We have introduced the concept of the linear-regression problem and the structure to solve it in a &amp;ldquo;machine-learning&amp;rdquo; fashion in this post, while we have applied the theory to a simple but practical case of linear-behavior identification from a bunch of data that are generated in a synthetic way here.
We now extend the analysis to a multi-linear case where more than one feature (or input) are fed to the model to predict the outcome.</description>
    </item>
    
    <item>
      <title>Hello world example for Machine learning - Part 2</title>
      <link>https://takeawildguess.net/blog/linreg/linreg2/</link>
      <pubDate>Sun, 13 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://takeawildguess.net/blog/linreg/linreg2/</guid>
      <description>1. Introduction We have introduced in the previous post the concept of the linear-regression problem and the structure to solve it in a &amp;ldquo;machine-learning&amp;rdquo; fashion. In this post we apply the theory to a simple but practical case of linear-behavior identification from a bunch of data that are generated in a synthetic way.
We are going to implement the logic from scratch in Python and its powerful numerical library, Numpy.</description>
    </item>
    
    <item>
      <title>Hello world example for Machine learning - Part 1</title>
      <link>https://takeawildguess.net/blog/linreg/linreg1/</link>
      <pubDate>Sun, 06 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://takeawildguess.net/blog/linreg/linreg1/</guid>
      <description>1. Problem formulation We want to create a simplified representation (model) of real/world from available data. The model architecture can be seen as a box that takes some quantities as input, performs some internal computation and returns some other quantities as output. The inputs are also referred to as features or predictors of the problem to solve, since they contain valuable information that the model should exploit to come up with the correct outcome.</description>
    </item>
    
    <item>
      <title>About me</title>
      <link>https://takeawildguess.net/about/me/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://takeawildguess.net/about/me/</guid>
      <description>I am passionate about AI and I have been developing some applications that could benefit from this new technique.
One of the first areas I started investigating the AI potential was my PhD research field. My work mainly focused on developing a simulation environment for Plug-in Hybrid Electric Vehicles and Hybrid Powertrain Optimal Control. After completing it in 2015, my goal as post-doc researcher was to develop machine learning algorithms for advance vehicle control, exploiting Vehicle-to-Infrastructure data.</description>
    </item>
    
    <item>
      <title>About the TWG project</title>
      <link>https://takeawildguess.net/about/about_twg/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://takeawildguess.net/about/about_twg/</guid>
      <description>This is my personal website where I will be publishing the main findings and outcomes of some research side-projects that I develop in my spare time. The overall scope of this project is to develop and describe what could be necessary to create some “smart agents”. As an agent, I literally mean someone/something that is capable of performing a task in a particular environment. Being smart entails achieving the final goal in a remarkable way.</description>
    </item>
    
    <item>
      <title>Skills</title>
      <link>https://takeawildguess.net/about/about_skills/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://takeawildguess.net/about/about_skills/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>