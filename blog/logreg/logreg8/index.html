<!DOCTYPE html>
<html lang="en-us">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  

   <meta name="description" content="Personal website"> 
   <meta name="author" content="Your name"> 
  

  <meta name="generator" content="Hugo 0.59.1" />
  <title>Learning to classify coffee from cappuccino - Part 8 &middot; take a wild guess</title>

  
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css"
integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">



 <link rel="stylesheet" href="https://takeawildguess.net/css/main.css"> 


<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway">


 <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/dracula.min.css"> 


<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">


<link rel="stylesheet" href="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.css">

  
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>

<script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script>



    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
     <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/go.min.js"></script>  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/haskell.min.js"></script>  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/kotlin.min.js"></script>  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/scala.min.js"></script>  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/swift.min.js"></script> 
    <script>hljs.initHighlightingOnLoad();</script>






<script>$(document).on('click', function() { $('.collapse').collapse('hide'); })</script>



<script type="text/javascript">
  window.onscroll = function() {myFunction()};
  function myFunction() {
    var winScroll = document.body.scrollTop || document.documentElement.scrollTop;
    var height = document.documentElement.scrollHeight - document.documentElement.clientHeight;
    var scrolled = (winScroll / height) * 100;
    document.getElementById("myBar").style.width = scrolled + "%";
  }
</script>


<script type="text/javascript">
  $(document).ready(function(){
    $(window).scroll(function () {
      if ($(this).scrollTop() > 50) { $('#back-to-top').fadeIn(); } else { $('#back-to-top').fadeOut(); }
    });
    
    $('#back-to-top').click(function () {
      $('#back-to-top').tooltip('hide');
      $('body,html').animate({ scrollTop: 0 }, 800); return false; });
    $('#back-to-top').tooltip('show');
  })
</script>


  
    <link href="//fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href="//fonts.googleapis.com/css?family=Kaushan+Script" rel="stylesheet" type="text/css">
    <link href="//fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic" rel="stylesheet" type="text/css">
    <link href="//fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700" rel="stylesheet" type="text/css">
  

  
    <link rel="shortcut icon" type="image/x-icon" href="https://takeawildguess.net/images/logo/twgLogo.png">
  

  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
  <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
  <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
  <![endif]-->

  
    
    
    
    
    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-151389132-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

    
  

  
  
  







<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']], displayMath: [['$$','$$']],
    processEscapes: true, processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" }, extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }});
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
  MathJax.Hub.Config({
  
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>

  

</head>

  <!-- Navigation -->
<nav class="navbar fixed-top navbar-expand-md navbar-dark bg-dark">
  
    <a class="navbar-brand abs" href="https://takeawildguess.net/">
      <img src="https://takeawildguess.net/images/logo/twgLogo.png" class="img-responsive" id="nav-logo" alt="Learning to classify coffee from cappuccino - Part 8">
    </a>
  
  <a class="navbar-brand" href="/blog/logreg/logreg8/" style="font-size: 16px; ">Coffee or cappuccino?</a>
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#collapsingNavbar">
      <span class="navbar-toggler-icon"></span>
  </button>
  <div class="navbar-collapse collapse" id="collapsingNavbar">
      <ul class="navbar-nav ml-auto">
        <li class="nav-item"><a class="nav-link" href="https://takeawildguess.net/">Home <span class="sr-only">(current)</span></a></li>
        <li class="nav-item"><a class="nav-link" href="https://takeawildguess.net/blog/">Blog</a></li>
        
        <li class="nav-item dropdown">
          <a class="nav-link dropdown-toggle" href="https://takeawildguess.net/about/" id="navbarDropdown" role="button"
          data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">About</a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
            <a class="dropdown-item" href="https://takeawildguess.net/about/">Main</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://takeawildguess.net/about/#a_twg">TWG</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://takeawildguess.net/about/#a_me">Me</a>
            <a class="dropdown-item" href="https://takeawildguess.net/about/#a_skl">Skills</a>
            <a class="dropdown-item" href="https://takeawildguess.net/about/#a_exp">Experience</a>
            <a class="dropdown-item" href="https://takeawildguess.net/about/#a_pt">Talks</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://takeawildguess.net/resume/">Resume</a>
          </div>
        </li>

        
      </ul>
      
      <ul class="navbar-nav navbar-right">
        
          <li class="nav-item navbar-icon"><a href="https://github.com/takeawildguess/" target="_blank"><i class="fa fa-github"></i></a></li>
        
          <li class="nav-item navbar-icon"><a href="https://twitter.com/takeawildguess4/" target="_blank"><i class="fa fa-twitter"></i></a></li>
        
          <li class="nav-item navbar-icon"><a href="https://www.linkedin.com/in/mattia-venditti-9137a124/" target="_blank"><i class="fa fa-linkedin"></i></a></li>
        
      </ul>
      
  </div>
  <div class="progress-container">
    <div class="progress-bar" id="myBar"></div>
  </div>
</nav>

  <body data-spy="scroll" data-target="#toc">
    <!-- Hero -->
<header class="postHead">
  <div class="container-fluid overlay">
    <div class="descr">
      <img src="https://takeawildguess.net/blog/images/coffee_cappuccino.jpeg" class="img-fluid" alt="__">
      <div class="card">
        <div class="card-body">
          <h1 class="card-title text-center">Learning to classify coffee from cappuccino - Part 8</h1>
          <h5 class="card-title text-center">Coffee or cappuccino?</h5>
          <h6 class="card-text text-center">April 7, 2019</h6>
          <h6 class="card-text text-center"><span class="fa fa-clock-o"></span> 10.5 min read</h6>
          <h6 class="card-text text-center">
            <a href="https://takeawildguess.net/tags/logistic-regression"><kbd class="item-tag">logistic-regression</kbd></a> <a href="https://takeawildguess.net/tags/algorithm"><kbd class="item-tag">algorithm</kbd></a> <a href="https://takeawildguess.net/tags/machine-learning"><kbd class="item-tag">machine learning</kbd></a> <a href="https://takeawildguess.net/tags/python"><kbd class="item-tag">python</kbd></a> <a href="https://takeawildguess.net/tags/scikit-learn"><kbd class="item-tag">scikit-learn</kbd></a> 
          </h6>
        </div>
      </div>
    </div>
  </div>
</header>

    <section class="postContent">
  <div class="container">
    <div class="row">
      
      <div class="col-sm-2 col-lg-2">
        <nav id="toc" data-toggle="toc" class="sticky-top"></nav>
      </div>
      
      <div class="col-lg-10 col-sm-10">
        <div class="container blogPost">
          

<h2 id="1-introduction-and-assumptions">1. Introduction and assumptions</h2>

<p>In this post-series, we are going to study the very basic modelling for classification problems with logistic regression algorithms.
<strong>Classification</strong> entails that the output is a discrete variable taking values on a predefined limited set, where the set dimension is the number of classes.
Some examples are <em>spam detection</em>, <em>object recognition</em> and <em>topic identification</em>.</p>

<p>We analyzed the theory in the <a href="/blog/logreg/logreg1/">first post</a>, implement the algorithm with Numpy in <a href="/blog/logreg/logreg2/">Part 2</a> and using Sklearn and Tensorflow in <a href="/blog/logreg/logreg3/">Part 3</a>.
We solved a binary classification problem for multivariate non-linear logistic regression in Scikit-learn in <a href="/blog/logreg/logreg4/">Part 4</a> and extended the analysis to multinomial classification in <a href="/blog/logreg/logreg5/">Part 5</a>.
After having played with the <a href="https://en.wikipedia.org/wiki/Tic-tac-toe" target="_blank">tic-tac-toe</a> gaming example in <a href="/blog/logreg/logreg6/">Part 6</a> and with the <code>digits</code> dataset in <a href="/blog/logreg/logreg7/">Part 7</a>, we shift to a bit harder problem, the <code>MNIST</code> dataset.</p>

<p>In this series, we do not split the dataset into training and testing sets, but we assess every model on the training set only.
A dedicated post on model selection, overfitting/underfitting problem and regularization will be published soon.</p>

<p>Let&rsquo;s get started!</p>

<h2 id="2-mnist-dataset-collection">2. MNIST dataset collection</h2>

<p>The amazing achievements on the <strong>digit</strong> dataset are also due to the very simple task we were trying to solve, which is not representative of common real-world machine-learning tasks.
We are going to introduce the MNIST dataset to increase the challenge by learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting.</p>

<p>We are going to retrieve the dataset from Yann LeCun <a href="http://yann.lecun.com/exdb/mnist/" target="_blank">page</a> and load it with the <code>input_data</code> module from TF.
You can follow <a href="https://chromium.googlesource.com/external/github.com/tensorflow/tensorflow/+/r0.7/tensorflow/g3doc/tutorials/mnist/download/index.md" target="_blank">this</a> tutorial to set everything up.</p>

<pre><code class="language-python">import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
</code></pre>

<pre><code class="language-python">mnist = input_data.read_data_sets(&quot;data/MNIST_data/&quot;, one_hot=True)
</code></pre>

<pre><code>Extracting MNIST_data/train-images-idx3-ubyte.gz
Extracting MNIST_data/train-labels-idx1-ubyte.gz
Extracting MNIST_data/t10k-images-idx3-ubyte.gz
Extracting MNIST_data/t10k-labels-idx1-ubyte.gz
</code></pre>

<p>The training and testing datasets contain 55k and 10k examples of (28x28) images, each stored as a flattened (784,) 1D array.</p>

<pre><code class="language-python">print(&quot;Training and testing dataset size: {} - {}&quot;.format(mnist.train.images.shape, mnist.test.images.shape))
</code></pre>

<pre><code>Training and testing dataset size: (55000, 784) - (10000, 784)
</code></pre>

<h2 id="3-data-preprocessing-and-visualization">3. Data preprocessing and visualization</h2>

<p>We extract 10 examples spanning 3 rows one to another.
We need to reshape each (784,) sample into a (28, 28) array to get a human easy-to-read image.</p>

<pre><code class="language-python">Ncls = 10
Nr, Nc, span = 2, 5, 3
Nel = Nr*Nc
plt.figure(figsize=(18,8))
for idx, (image, label) in enumerate(zip(mnist.train.images[0:Nel*span:span], mnist.train.labels[0:Nel*span:span])):
    plt.subplot(Nr, Nc, idx + 1)
    plt.imshow(image.reshape(-1, 28), cmap='Blues')
    plt.title('Label %i\n' % np.where(label==1), fontsize = 16)
</code></pre>

<p><img src="output_8_0.png" alt="png" /></p>

<p>We create a Python dictionary with 10 keys, one for each class.
The corresponding value stores the first encountered image for that class.
The current label is extracted from the one-hot encoding by using the Numpy <code>where</code> function.</p>

<pre><code class="language-python">spectro = {}
kk = 0
while len(spectro) &lt; 10:
    currLabel = str(np.where(mnist.train.labels[kk])[0][0])
    if currLabel not in spectro:
        spectro[currLabel] = mnist.train.images[kk]
    kk += 1
</code></pre>

<p>The figure shows a kind of spectrogram of the first image example of the 10 different classes that are stored in <code>spectro</code>.</p>

<pre><code class="language-python">plt.figure(figsize=(17, 9))
for kk, (label, img) in enumerate(spectro.items()):
    plt.subplot(2, 5, kk+1)
    plt.imshow(img.reshape(-1, 1), cmap='gist_gray', aspect=0.002)
    plt.xticks([])
    plt.title('Label: ' + label, fontsize = 16)
</code></pre>

<p><img src="output_12_0.png" alt="png" /></p>

<p>In this step, we want to retrieve the <em>average</em> image of each class.
We convert the one-hot encoding to a label encoding by identifying where the only 1 of each label is located.
Within a for-loop through the 10 classes, we take only images related to one specific class.
The rows of the image matrix that correspond to a given class are selected, the average array is obtained by executing the mean along the rows (<code>axis=0</code>) and it is reshaped to get the actual image format.</p>

<p>To get more details about the powerful indexing operation available in Numpy, visit <a href="https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html#boolean-array-indexing" target="_blank">this</a> docs.</p>

<pre><code class="language-python">Ycls = np.argmax(mnist.train.labels==1, axis=1)
</code></pre>

<pre><code class="language-python">plt.figure(figsize=(17, 9))
for kk in range(10):
    plt.subplot(2, 5, kk+1)
    plt.imshow(np.mean(mnist.train.images[Ycls==kk, :], axis=0).reshape(-1, 28), cmap='Blues')
    plt.title('Label: ' + str(kk), fontsize = 16)
</code></pre>

<p><img src="output_15_0.png" alt="png" /></p>

<h2 id="4-correlation-of-the-10-classes">4. Correlation of the 10 classes</h2>

<p>We group the 10 average arrays (images) into a list and build a 2D array where row <code>i</code> and column <code>j</code> represent the <a href="https://en.wikipedia.org/wiki/Dot_product" target="_blank">scalar product</a> between the average arrays of classes <code>i</code> and <code>j</code>.
It is clear that this matrix is symmetric.</p>

<pre><code class="language-python">meanArrays = [np.mean(mnist.train.images[Ycls==kk, :], axis=0) for kk in range(10)]
</code></pre>

<pre><code class="language-python">corrs = np.zeros((10, 10))
for k1 in range(10):
    for k2 in range(10):
        corrs[k1, k2] = np.dot(meanArrays[k1], meanArrays[k2])
</code></pre>

<pre><code class="language-python">plt.imshow(corrs, cmap='Blues')
</code></pre>

<pre><code>&lt;matplotlib.image.AxesImage at 0x1ee4af835c0&gt;
</code></pre>

<p><img src="output_19_1.png" alt="png" /></p>

<p>We take the highest correlating product along the 0-axis and realize that class 1 average image is highly correlated to class 8, while class 5 to class 0.</p>

<pre><code class="language-python">print(&quot;Highest-correlated classes for each of the 10 classes\n{}&quot;.format(np.argmax(corrs, axis=0)))
</code></pre>

<pre><code>Highest-correlated classes for each of the 10 classes
[0 8 2 3 4 0 6 7 8 9]
</code></pre>

<h2 id="5-building-the-logistic-regression-model-in-tensorflow">5 Building the logistic regression model in Tensorflow</h2>

<p>The loss function is easily implemented using the method <code>sigmoid_cross_entropy_with_logits</code> from <code>losses</code> package.
The optimizer object that actually adjusts the model parameters (TF variables) with the gradient descent algorithm.</p>

<p>The next steps to <strong>train</strong> the model are to:
1. initialize the variables.
2. run a new session, which let us perform the actual computation by exploiting the graph structure previously defined.
3. run the optimizer as many steps as the number of epochs <code>Nepoch</code>.
4. run the model with the final parameter set and store the model output <code>ymdl</code> into the prediction array.
5. retrieve the final parameter values by running a dedicated session. A different way would be to call the <a href="https://www.tensorflow.org/api_docs/python/tf/global_variables" target="_blank">global_variables()</a> method and get the variable values by key name.</p>

<pre><code class="language-python">Nfeat, Ncls = 784, 10
tf.reset_default_graph()
xp = tf.placeholder(dtype=tf.float32, shape=(None, 784))
yp = tf.placeholder(dtype=tf.float32, shape=(None, Ncls))
ww = tf.Variable(np.zeros((784, 10)), dtype=tf.float32)
bb = tf.Variable(tf.zeros([10]))
ymdl = tf.matmul(xp, ww) + bb

ypred = tf.argmax(tf.sigmoid(ymdl),1)
yact = tf.argmax(yp,1)

accuracy = tf.reduce_mean(tf.cast(tf.equal(ypred, yact), dtype=tf.float32))
mdlLoss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=ymdl, labels=yp))
optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss=mdlLoss)
# GradientDescentOptimizer
</code></pre>

<pre><code class="language-python">print('Input shape: {}'.format(xp.shape))
print('Ground-truth output shape: {}'.format(yp.shape))
print('Weight shape: {}'.format(ww.shape))
print('Model output shape: {}'.format(ymdl.shape))
</code></pre>

<pre><code>Input shape: (?, 784)
Ground-truth output shape: (?, 10)
Weight shape: (784, 10)
Model output shape: (?, 10)
</code></pre>

<h2 id="6-training-the-model">6. Training the model</h2>

<p>We train the model for 200 steps, defined by the number of epochs <code>Nepoch</code>, until we get a model accuracy of 90%.</p>

<pre><code class="language-python">Nepoch = 200
Nbtc = 100 # number of batches
init = tf.global_variables_initializer()
XX, Yclass = mnist.train.images, mnist.train.labels
with tf.Session() as sess:
    sess.run(init)
    Jevol = []
    for kk in range(Nepoch):
        Xbatch, Ybatch = mnist.train.next_batch(Nbtc)
        mdl_loss, _ = sess.run([mdlLoss, optimizer], feed_dict={xp: Xbatch, yp: Ybatch})
        if kk%50 == 0:
            Jevol.append((kk, mdl_loss))
            print('The current model loss is {}'.format(mdl_loss))
        if kk==Nepoch-1:
            print('The final model loss is {}'.format(mdl_loss))
            trainAcc = sess.run([accuracy], feed_dict={xp: mnist.train.images, yp: mnist.train.labels})[0]
            print('The final model accuracy is {}'.format(trainAcc))
    
    Wcoef = sess.run(ww, feed_dict={xp: XX, yp: Yclass})
    Ypred_tf, Yact = sess.run([ypred, yact], feed_dict={xp: XX, yp: Yclass})
    mdlAcc = sess.run([accuracy], feed_dict={xp: XX, yp: Yclass})[0]
</code></pre>

<pre><code>The current model loss is 2.3025853633880615
The current model loss is 0.3165014386177063
The current model loss is 0.4505566358566284
The current model loss is 0.25453245639801025
The final model loss is 0.3332114517688751
The final model accuracy is 0.9073818325996399
</code></pre>

<pre><code class="language-python">print(&quot;Accuracy: {}&quot;.format(metrics.accuracy_score(Yact, Ypred_tf)))
print(&quot;Precision: {}&quot;.format(metrics.precision_score(Yact, Ypred_tf, average='weighted')))
print(&quot;Recall: {}&quot;.format(metrics.recall_score(Yact, Ypred_tf, average='weighted')))
</code></pre>

<pre><code>Accuracy: 0.9073818181818182
Precision: 0.9079350099345992
Recall: 0.9073818181818182
</code></pre>

<h2 id="7-model-accuracy">7. Model accuracy</h2>

<p>We define the confusion matrix also for the MNIST case.
For the sake of readability, we set the diagonal values to NaN to prevent everything else to collapse to the bottom colormap (green).</p>

<pre><code class="language-python">cm = metrics.confusion_matrix(Yact, Ypred_tf)
</code></pre>

<pre><code class="language-python">cmDisp = cm.astype(float)
#cmDisp[cmDisp==0] = np.nan
cmDisp[np.diag_indices(Ncls)] = np.nan

plt.figure(figsize=(9,9))
plt.imshow(cmDisp, interpolation='nearest', cmap='Set2') # cmap='Pastel1'
plt.title('Confusion matrix', size = 15)
plt.colorbar()
tickMarks = np.arange(10)
tickLabels = [str(num) for num in range(10)]
plt.xticks(tickMarks, tickLabels, size = 10, fontsize=12)
plt.yticks(tickMarks, tickLabels, size = 10, fontsize=12)
plt.tight_layout()
plt.ylabel('Actual label', size = 15)
plt.xlabel('Predicted label', size = 15)
width, height = cm.shape
for x in range(width):
    for y in range(height):
        plt.annotate(str(cm[x][y]), xy=(y, x), horizontalalignment='center', verticalalignment='center')
</code></pre>

<p><img src="output_30_0.png" alt="png" /></p>

<h2 id="8-error-analysis">8. Error analysis</h2>

<p>In this section, we analyze the misclassified images. The figure shows 12 cases, where each chart reports the actual and predicted classes of the corresponding image.</p>

<pre><code class="language-python">misclassified = np.where(Yact != Ypred_tf)[0]
</code></pre>

<pre><code class="language-python">Nr, Nc, span = 3, 4, 3
Nel = Nr*Nc
plt.figure(figsize=(18,14))
for qq, idx in enumerate(misclassified[:Nel*span:span]):
    img, label = mnist.train.images[idx], mnist.train.labels[idx]
    plt.subplot(Nr, Nc, qq+1)
    plt.imshow(img.reshape(-1, 28), cmap='Blues')
    plt.title('Actual/predicted labels: {}/{}'.format(str(Yact[idx]), str(Ypred_tf[idx])), fontsize = 14)
</code></pre>

<p><img src="output_33_0.png" alt="png" /></p>

<p>This step is one of the most important in the machine-learning field.
To analyze the model errors and try to come up with new ideas either to change the architecture or the hyperparameters of the model itself.
We can clearly spot how frequently class <code>5</code> has been misclassified.
This fact is coherent with poor correlation for class <code>5</code> with itself.
Recall that it was indeed more correlated to class <code>0</code>.</p>

<h2 id="9-model-parameter-analysis">9. Model parameter analysis</h2>

<p>In the final section, we display the model parameter (or weight) values stored in the <code>(784,10)</code> 2D array <code>Wcoef</code>.
We can treat this 2D array as a horizontal concatenation of 10 <code>(784,)</code> 1D arrays, one for each class.
Each 1D array stores the weights of every pixel of the image, out of the 784 total ones.
If we reshape this 1D array, we can visually get the alignment between the pixel (inputs) and the weight.
It is very fascinating how the weight contour plot matches the input structure in such a way for you to easily read the class number.</p>

<pre><code class="language-python">plt.figure(figsize=(17, 9))
for kk in range(10):
    plt.subplot(2, 5, kk+1)
    plt.imshow(Wcoef[:, kk].reshape(-1, 28), cmap='Blues')
    plt.title('Label: ' + str(kk), fontsize = 16)
</code></pre>

<p><img src="output_36_0.png" alt="png" /></p>

<p>We did some tests on the parameters&rsquo; space shape when the training is much shorter.
We stopped the process when the accuracy was only 80%.
It is very fascinating how the weight contour plot matches even more strongly the input structure.</p>

<pre><code class="language-python">plt.figure(figsize=(17, 9))
for kk in range(10):
    plt.subplot(2, 5, kk+1)
    plt.imshow(Wcoef[:, kk].reshape(-1, 28), cmap='Blues')
    plt.title('Label: ' + str(kk), fontsize = 16)
</code></pre>

<p><img src="output_38_0.png" alt="png" /></p>

        </div>
        <div class="pgNav PageNavigation col-12 text-center">
          <span>
          <p>&laquo; <a class="" href="/blog/logreg/logreg7/" style="color: #4ABDAC; font-size: 18px; "> Learning to classify coffee from cappuccino - Part 7</a>
          
          &nbsp;&nbsp; | &nbsp;&nbsp;
          <a class="" href="/blog/mdlsel/mdlsel1/" style="color: #4ABDAC; font-size: 18px; ">Do not overlearn your data too much, learn to generalize - Part 1</a>
          
          &raquo;</p>
          </span>
          
          
        </div>
      </div>
    </div>
  </div>
</section>

    <div class="article-container">
      <script src="https://utteranc.es/client.js"
        repo="takeawildguess/pws"
        issue-term="pathname"
        label="Comment"
        theme="github-dark-orange"
        crossorigin="anonymous"
        async>
</script>

    </div>

    
    

    



    <footer class="pgFoot">
  <div class="container-fluid">
    <div class="row">
      <div class="col-12 text-center icons">
        
        <span>
          <a href="https://github.com/takeawildguess/"><i class="fa fa-github"></i></a><a href="https://twitter.com/takeawildguess4/"><i class="fa fa-twitter"></i></a><a href="https://www.linkedin.com/in/mattia-venditti-9137a124/"><i class="fa fa-linkedin"></i></a>
        </span>
        
      </div>

      <hr style="border: 2px solid #4ABDAC; min-width: 250px; border-radius: 2px; " />
      <div class="col-12 text-center">
        <p>
          &bull; Copyright &copy; 2019, <a href="https://takeawildguess.net/">Mattia Venditti</a> &bull; All rights reserved. &bull;
          <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">
            <img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" />
          </a>
          All blog posts are released under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">
            Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
        </p>
      </div>
      

      <div class="col-6 text-center">
        <p>Disclaimer: The views and opinions on this website are my own and do not reflect or represent the views of my employer.</p>
      </div>
      <div class="col-6 text-center">
        <p>
        Powered by <a href="https://gohugo.io/">Hugo</a> and <a href="https://pages.github.com/">GitHub Pages</a>.
        The favicon and logo were created by myself.
        </p>
      </div>

    </div>
  </div>
</footer>

<a id="back-to-top" href="https://takeawildguess.net/" class="btn btn-primary btn-lg back-to-top" role="button" title="Click to return on the top page"
data-toggle="tooltip" data-placement="left"><i class="fa fa-angle-up"></i></a>


  </body>
</html>
