<!DOCTYPE html>
<html lang="en-us">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  

   <meta name="description" content="Personal website"> 
   <meta name="author" content="Your name"> 
  

  <meta name="generator" content="Hugo 0.59.1" />
  <script type="application/ld+json">
{
    "@context" : "http://schema.org",
    "@type" : "BlogPosting",
    "mainEntityOfPage": {
         "@type": "WebPage",
         "@id": "https://takeawildguess.net/"
    },
    "articleSection" : "blog",
    "name" : "Hello world for Machine learning - Part 4",
    "headline" : "Hello world for Machine learning - Part 4",
    "description" : "1. Introduction We have introduced the concept of the linear-regression problem and the structure to solve it in a \x26ldquo;machine-learning\x26rdquo; fashion in this post, while we have applied the theory to a simple but practical case of linear-behaviour identification from a bunch of data that are generated in a synthetic way here and extend the analysis to a multi-linear case where more than one feature (or input) are fed to the model to predict the outcome here.",
    "inLanguage" : "en-US",
    "author" : "Mattia Venditti",
    "creator" : "Mattia Venditti",
    "publisher" : "Mattia Venditti",
    "accountablePerson" : "Mattia Venditti",
    "copyrightHolder" : "Mattia Venditti",
    "copyrightYear" : "2019",
    "datePublished": "2019-02-03T00:00:00Z",
    "dateModified" : "2019-02-03T00:00:00Z",
    "url" : "https://takeawildguess.net/blog/linreg/linreg4/",
    "wordCount" : "1958",
    "keywords" : [ "linear-regression","algorithm","machine learning","python","scikit-learn","tensorflow","Blog" ]
}
</script>

  <title>Hello world for Machine learning - Part 4 &middot; take a wild guess</title>

  
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css"
integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">



 <link rel="stylesheet" href="https://takeawildguess.net/css/main.css"> 


<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway">


 <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/dracula.min.css"> 


<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">


<link rel="stylesheet" href="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.css">

  
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>

<script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script>



    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
     <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/go.min.js"></script>  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/haskell.min.js"></script>  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/kotlin.min.js"></script>  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/scala.min.js"></script>  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/swift.min.js"></script> 
    <script>hljs.initHighlightingOnLoad();</script>






<script>$(document).on('click', function() { $('.collapse').collapse('hide'); })</script>



<script type="text/javascript">
  window.onscroll = function() {myFunction()};
  function myFunction() {
    var winScroll = document.body.scrollTop || document.documentElement.scrollTop;
    var height = document.documentElement.scrollHeight - document.documentElement.clientHeight;
    var scrolled = (winScroll / height) * 100;
    document.getElementById("myBar").style.width = scrolled + "%";
  }
</script>


<script type="text/javascript">
  $(document).ready(function(){
    $(window).scroll(function () {
      if ($(this).scrollTop() > 50) { $('#back-to-top').fadeIn(); } else { $('#back-to-top').fadeOut(); }
    });
    
    $('#back-to-top').click(function () {
      $('#back-to-top').tooltip('hide');
      $('body,html').animate({ scrollTop: 0 }, 800); return false; });
    $('#back-to-top').tooltip('show');
  })
</script>


  
    <link href="//fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href="//fonts.googleapis.com/css?family=Kaushan+Script" rel="stylesheet" type="text/css">
    <link href="//fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic" rel="stylesheet" type="text/css">
    <link href="//fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700" rel="stylesheet" type="text/css">
  

  
    <link rel="shortcut icon" type="image/x-icon" href="https://takeawildguess.net/images/logo/twgLogo.png">
  

  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
  <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
  <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
  <![endif]-->

  
    
    
    
    
    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-151389132-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

    
  

  
  
  







<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']], displayMath: [['$$','$$']],
    processEscapes: true, processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" }, extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }});
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
  MathJax.Hub.Config({
  
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>

  

</head>

  <!-- Navigation -->
<nav class="navbar fixed-top navbar-expand-md navbar-dark bg-dark">
  
    <a class="navbar-brand abs" href="https://takeawildguess.net/">
      <img src="https://takeawildguess.net/images/logo/twgLogo.png" class="img-responsive" id="nav-logo" alt="Hello world for Machine learning - Part 4">
    </a>
  
  <a class="navbar-brand" href="/blog/linreg/linreg4/" style="font-size: 16px; ">Hello world</a>
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#collapsingNavbar">
      <span class="navbar-toggler-icon"></span>
  </button>
  <div class="navbar-collapse collapse" id="collapsingNavbar">
      <ul class="navbar-nav ml-auto">
        <li class="nav-item"><a class="nav-link" href="https://takeawildguess.net/">Home <span class="sr-only">(current)</span></a></li>
        <li class="nav-item"><a class="nav-link" href="https://takeawildguess.net/blog/">Blog</a></li>
        
        <li class="nav-item dropdown">
          <a class="nav-link dropdown-toggle" href="https://takeawildguess.net/about/" id="navbarDropdown" role="button"
          data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">About</a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
            <a class="dropdown-item" href="https://takeawildguess.net/about/">Main</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://takeawildguess.net/about/#a_twg">TWG</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://takeawildguess.net/about/#a_me">Me</a>
            <a class="dropdown-item" href="https://takeawildguess.net/about/#a_skl">Skills</a>
            <a class="dropdown-item" href="https://takeawildguess.net/about/#a_exp">Experience</a>
            <a class="dropdown-item" href="https://takeawildguess.net/about/#a_pt">Talks</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://takeawildguess.net/resume/">Resume</a>
          </div>
        </li>

        
      </ul>
      
      <ul class="navbar-nav navbar-right">
        
          <li class="nav-item navbar-icon"><a href="https://github.com/takeawildguess/" target="_blank"><i class="fa fa-github"></i></a></li>
        
          <li class="nav-item navbar-icon"><a href="https://twitter.com/takeawildguess4/" target="_blank"><i class="fa fa-twitter"></i></a></li>
        
          <li class="nav-item navbar-icon"><a href="https://www.linkedin.com/in/mattia-venditti-9137a124/" target="_blank"><i class="fa fa-linkedin"></i></a></li>
        
      </ul>
      
  </div>
  <div class="progress-container">
    <div class="progress-bar" id="myBar"></div>
  </div>
</nav>

  <body data-spy="scroll" data-target="#toc">
    <!-- Hero -->
<header class="postHead">
  <div class="container-fluid overlay">
    <div class="descr">
      <img src="https://takeawildguess.net/blog/images/hello.jpeg" class="img-fluid" alt="__">
      <div class="card">
        <div class="card-body">
          <h1 class="card-title text-center">Hello world for Machine learning - Part 4</h1>
          <h5 class="card-title text-center">Hello world</h5>
          <h6 class="card-text text-center">February 3, 2019</h6>
          <h6 class="card-text text-center"><span class="fa fa-clock-o"></span> 13 min read</h6>
          <h6 class="card-text text-center">
            <a href="https://takeawildguess.net/tags/linear-regression"><kbd class="item-tag">linear-regression</kbd></a> <a href="https://takeawildguess.net/tags/algorithm"><kbd class="item-tag">algorithm</kbd></a> <a href="https://takeawildguess.net/tags/machine-learning"><kbd class="item-tag">machine learning</kbd></a> <a href="https://takeawildguess.net/tags/python"><kbd class="item-tag">python</kbd></a> <a href="https://takeawildguess.net/tags/scikit-learn"><kbd class="item-tag">scikit-learn</kbd></a> <a href="https://takeawildguess.net/tags/tensorflow"><kbd class="item-tag">tensorflow</kbd></a> 
          </h6>
        </div>
      </div>
    </div>
  </div>
</header>

    <section class="postContent">
  <div class="container">
    <div class="row">
      
      <div class="col-sm-2 col-lg-2">
        <nav id="toc" data-toggle="toc" class="sticky-top"></nav>
      </div>
      
      <div class="col-lg-10 col-sm-10">
        <div class="container blogPost">
          

<h2 id="1-introduction">1. Introduction</h2>

<p>We have introduced the concept of the linear-regression problem and the structure to solve it in a &ldquo;machine-learning&rdquo; fashion in <a href="/blog/linreg/linreg1/">this</a> post, while we have applied the theory to a simple but practical case of linear-behaviour identification from a bunch of data that are generated in a synthetic way <a href="/blog/linreg/linreg2/">here</a> and extend the analysis to a multi-linear case where more than one feature (or input) are fed to the model to predict the outcome <a href="/blog/linreg/linreg3/">here</a>.</p>

<p>We now face the implementation process with popular libraries available in the Python framework, namely <a href="https://scikit-learn.org/stable/" target="_blank">Sklearn</a> and <a href="https://www.tensorflow.org/" target="_blank">Tensorflow</a>.</p>

<p>Scikit-learn is a free software machine learning library for the Python programming language. It enables fast implementation of several classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting and k-means, and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy.</p>

<p>TensorFlow is an open-source software library for dataflow programming across a range of tasks. It is a symbolic math library, and is mainly employed for machine learning applications and more recently deep learning modeling. It is developed by the <a href="https://ai.google/research/teams/brain" target="_blank">Google Brain</a> team.</p>

<p>Code-wise, such libraries let developers focus more on the model itself and achieving an overall better performance by optimizing the model hyper-parameters and by combining different models to deliver an ensemble version out of it.</p>

<p>We are going to implement the logic in Scikit-learn (SKL) first and then in Tensorflow (TF) in this post, while the next <a href="/blog/linreg/linreg5/">one</a> treats fundamental aspects of machine learning theory, such as feature scaling, feature augmentation, via techniques such as polynomial features, and hypothesis evaluation.</p>

<h2 id="2-data-generation">2. Data generation</h2>

<p>We are going to build three datasets:</p>

<ol>
<li>A multi-linear model of two inputs.</li>
<li>A multi-linear model of two inputs, where one input outscales the other one.</li>
<li>A multi-linear model of two inputs, where one of them represents polynomial features.</li>
</ol>

<h3 id="2-1-a-multi-linear-model-of-two-inputs">2.1 A multi-linear model of two inputs</h3>

<p>We start generating some synthetic data (<code>Npntx*Npnty=50*50</code> points).
We assume we know both the slope of the two inputs ($ \omega_1 = 3, \omega_2 = -1 $) and the intercept ($ \omega_0 = 5 $) of the plane we want to identify, but we also introduce some noise with a gaussian distribution and zero-mean to the plane to make the data source a bit closer to real-world scenarios.
The chart shows the generated data cloud (see <a href="/blog/linreg/linreg3/">this</a> post for further details).
Here follows the mathematical expression of the model:</p>

<p>$$ y = \omega_0 + \omega_1\cdot x_1 + \omega_2\cdot x_2 $$</p>

<pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
import pandas as pd
from mpl_toolkits import mplot3d
</code></pre>

<pre><code class="language-python">Npntx, Npnty = 50, 50 # number of points
x1_ = np.linspace(-1, 1, Npntx)
x2_ = np.linspace(-1, 1, Npnty)
xx1, xx2 = np.meshgrid(x1_, x2_)
noise = 0.25*(np.random.randn(Npnty,Npntx)-1)
w0, w1, w2 = 5, -3, -1
yy = w0 + w1*xx1 + w2*xx2 + noise
zz = w0 + w1*xx1 + w2*xx2
visData1 = [xx1, xx2, yy, [w0, w1, w2]]
</code></pre>

<pre><code class="language-python">plt.figure(figsize=(10, 5))
ax = plt.axes(projection='3d')
ax.plot_surface(xx1, xx2, zz, rstride=1, cstride=1, cmap='viridis', edgecolor='none', alpha=0.5)
ax.scatter(xx1, xx2, yy, cmap='viridis', linewidth=0.5, alpha=0.5)
plt.xlabel(&quot;X1&quot;)
plt.ylabel(&quot;X2&quot;)
plt.ylabel(&quot;Y&quot;)

ax.set_xlabel('x1')
ax.set_ylabel('x2')
ax.set_zlabel('y')
ax.view_init(30, 35)
plt.show()
</code></pre>

<p><img src="output_5_0.png" alt="png" /></p>

<p>The dataset is generated by creating two 2D arrays, one for inputs and one for outputs.
The input array, <code>XX</code>, is the horizontal concatenation of the flattened version of the two input arrays, <code>xx1</code> and <code>xx2</code>.
There is no need to add the column filled with 1s, as we had to do in the Numpy implementation.</p>

<p>We first stack the two 1D arrays vertically and then transpose it to get the examples (<code>50*30=1500</code>) over the rows and the features over the columns (2).</p>

<p>The output 2D array is just a single column filled with the <code>y</code> values. Here the shape of the arrays.</p>

<pre><code class="language-python">XX1 = np.vstack((xx1.flatten(), xx2.flatten())).T
YY1 = yy.flatten().reshape(-1,1)
print([XX1.shape, YY1.shape])
</code></pre>

<pre><code>[(2500, 2), (2500, 1)]
</code></pre>

<h3 id="2-2-a-multi-linear-model-of-two-inputs-where-one-input-outscales-the-other-one">2.2 A multi-linear model of two inputs, where one input outscales the other one</h3>

<p>We generate some synthetic data (<code>Npntx*Npnty=50*50</code> points), but we make sure one input maximum value is far greater than the other one. In particular, <code>x1</code> scales from -1000 to 1000, while <code>x2</code> from -1 to 1.
However, the mathematical correlation does not change:</p>

<p>$$ y = \omega_0 + \omega_1\cdot x_1 + \omega_2\cdot x_2 $$</p>

<p>In a real-life task, it is common to face such situations. Credit risk management is one example, where some inputs to the model could be how many employees work for the company that should take the loan, and the annual revenue.
The order of magnitude of the latter is way too greater than the former, in general.</p>

<p>You can see in the below chart how the second input looks like to have no impact on the outcome of the model.</p>

<pre><code class="language-python">Npntx, Npnty = 50, 50 # number of points
x1_ = np.linspace(-100, 100, Npntx)
x2_ = np.linspace(-1, 1, Npnty)
xx1, xx2 = np.meshgrid(x1_, x2_)
noise = 0.25*(np.random.randn(Npnty,Npntx)-1)
w0, w1, w2 = 2, -3, -1
yy = w0 + w1*xx1 + w2*xx2 + noise
zz = w0 + w1*xx1 + w2*xx2
visData2 = [xx1, xx2, yy, [w0, w1, w2]]
</code></pre>

<pre><code class="language-python">plt.figure(figsize=(10, 5))
ax = plt.axes(projection='3d')
ax.plot_surface(xx1, xx2, zz, rstride=1, cstride=1, cmap='viridis', edgecolor='none', alpha=0.5)

ax.scatter(xx1, xx2, yy, cmap='viridis', linewidth=0.5, alpha=0.5)
plt.xlabel(&quot;X1&quot;)
plt.ylabel(&quot;X2&quot;)
plt.ylabel(&quot;Y&quot;)
ax.set_xlabel('x1')
ax.set_ylabel('x2')
ax.set_zlabel('y')
ax.view_init(30, 35)
plt.show()
</code></pre>

<p><img src="output_10_0.png" alt="png" /></p>

<p>The dataset is generated with the same procedure.</p>

<pre><code class="language-python">XX2 = np.vstack((xx1.flatten(), xx2.flatten())).T
YY2 = yy.flatten().reshape(-1,1)
print([XX2.shape, YY2.shape])
</code></pre>

<pre><code>[(2500, 2), (2500, 1)]
</code></pre>

<h3 id="2-3-a-multi-linear-model-of-two-inputs-where-one-of-them-represents-polynomial-features">2.3 A multi-linear model of two inputs, where one of them represents polynomial features.</h3>

<p>We generate some synthetic data (<code>Npntx*Npnty=50*50</code> points), where the first feature <code>x1</code> shows off as a quadratic function.
The mathematical correlation is as follows:</p>

<p>$$ y = \omega_0 + \omega_1\cdot x_1 + \omega_2\cdot x_1^2 + \omega_3\cdot x_2 $$</p>

<p>In real-life task, it is common to face such situations. Joule heating is one example, where the heat released by a light bulb is correlated to the square of the electric current through the wires.</p>

<p>You can see in the below chart how the first input is responsible for the curvature of the generated surface.</p>

<pre><code class="language-python">Npntx, Npnty = 50, 50 # number of points
x1_ = np.linspace(-5, 5, Npntx)
x2_ = np.linspace(-5, 5, Npnty)
xx1, xx2 = np.meshgrid(x1_, x2_)
noise = 0.25*(np.random.randn(Npnty,Npntx)-1)
w0, w1, w2, w3 = 2, -3, -1, 2
yy = w0 + w1*xx1 + w2*xx1**2 + w3*xx2 + noise
zz = w0 + w1*xx1 + w2*xx1**2 + w3*xx2
visData3 = [xx1, xx2, yy, [w0, w1, w2, w3]]
</code></pre>

<pre><code class="language-python">plt.figure(figsize=(10, 5))
ax = plt.axes(projection='3d')
ax.plot_surface(xx1, xx2, zz, rstride=1, cstride=1, cmap='viridis', edgecolor='none', alpha=0.5)

ax.scatter(xx1, xx2, yy, cmap='viridis', linewidth=0.5, alpha=0.5)
plt.xlabel(&quot;X1&quot;)
plt.ylabel(&quot;X2&quot;)
plt.ylabel(&quot;Y&quot;)

ax.set_xlabel('x1')
ax.set_ylabel('x2')
ax.set_zlabel('y')
ax.view_init(30, 35)
plt.show()
</code></pre>

<p><img src="output_15_0.png" alt="png" /></p>

<p>The dataset is generated with the same procedure.</p>

<pre><code class="language-python">XX3 = np.vstack((xx1.flatten(), xx1.flatten()**2, xx2.flatten())).T
YY3 = yy.flatten().reshape(-1,1)
print([XX3.shape, YY3.shape])
</code></pre>

<pre><code>[(2500, 3), (2500, 1)]
</code></pre>

<h2 id="3-linear-regression-with-scikit-learn">3. Linear regression with Scikit-learn</h2>

<p>We import the module required to define the linear model, <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html" target="_blank"><strong>LinearRegression</strong></a>, from the <code>linear_model</code> package, and the module to evaluate the performance of the model, <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html" target="_blank"><strong>RMSE</strong></a>, from the <code>metrics</code> package.
It is enough to fit the model parameters to the first dataset and to calculate the model prediction for the inputs of each sample of the same dataset.</p>

<p>We can realize (and appreciate) how the overall code ends up being much more compact and easier to write and maintain.</p>

<pre><code class="language-python">from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
</code></pre>

<pre><code class="language-python">lm = LinearRegression()
</code></pre>

<pre><code class="language-python">lm.fit(XX1, YY1)
Ypred = lm.predict(XX1)
print('The final RSME is : {}'.format(mean_squared_error(YY1, Ypred)))
print('The final parameter values: {}'.format(np.hstack((lm.intercept_, lm.coef_[0,:])).tolist()))
</code></pre>

<pre><code>The final RSME is : 0.060867550456315374
The final parameter values: [4.753763678286057, -3.001900368199036, -1.0124158793115567]
</code></pre>

<pre><code class="language-python">xx1, xx2, yy = visData1
ypred = Ypred.reshape(-1, xx1.shape[-1])
plt.figure(figsize=(10, 5))
ax = plt.axes(projection='3d')
ax.plot_surface(xx1, xx2, ypred, rstride=1, cstride=1, cmap='viridis', edgecolor='none', alpha=0.5)
ax.scatter(xx1, xx2, yy, cmap='viridis', linewidth=0.5, alpha=0.5)
ax.set_xlabel('$x_1$')
ax.set_ylabel('$x_2$')
ax.set_zlabel('y')
ax.view_init(20, 30)

plt.tight_layout()
plt.show()
</code></pre>

<p><img src="output_22_0.png" alt="png" /></p>

<p>In three lines of Python code, we are now able to perform what requires a lot of effort and coding when starting from scratch.</p>

<h2 id="4-linear-regression-with-tensorflow">4. Linear regression with TensorFlow</h2>

<p>We import the entire library, from which we access to the various methods required to describe the model, to train it to the dataset and to estimate the outputs that are compared to the dataset ground-truth values.</p>

<h3 id="4-1-model-definition">4.1 Model definition</h3>

<p>The very first step is to reset the TF to the default graph, which means TF clears the default graph stack and resets the global default graph.</p>

<p>We then define the <code>x</code> and <code>y</code> variables as <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder" target="_blank"><code>placeholder</code></a>, while the <code>ww</code> parameters as <a href="https://www.tensorflow.org/guide/variables" target="_blank"><code>variable</code></a>.</p>

<p>In short, <code>tf.Variable</code> is used for trainable parameters of the model, while <code>tf.placeholder</code> is used to feed actual training examples.
That&rsquo;s why we need to assign initial values, often random-generated, to the TF variables only.
The variable values can therefore be updated during optimization, can be shared and be stored after training.
We assign the placeholder type as <code>float32</code> to both input and output.
The size of the input placeholder, <code>xp</code>, is set to (None, 2), since the number of rows is automatically determined from the batch size we feed to the optimizer object in the training step, while the column size is equal to the number of features (2 for the first case).
The size of the output placeholder is instead set to (None, 1), since only one value is required for each sample.</p>

<p>The feature weights <code>ww</code> and bias <code>bb</code>, which is equivalent to the Sk-Learn intercept, are defined with the <code>Variable</code> method and initialized as a (2,1) and a (1,1) zero-arrays, respectively.</p>

<p>The final step is to combine TF variables and placeholders to translate the mathematical model into code.
The matrix multiplication between the input matrix and the weight array is performed with <code>matmul</code>.
At the end of these steps, we inspect the shape of each tensor.
The question-mark symbol says that TF needs some data to determine the actual row size.</p>

<pre><code class="language-python">import tensorflow as tf
</code></pre>

<pre><code class="language-python">tf.reset_default_graph()
xp = tf.placeholder(dtype=tf.float32, shape=(None, 2))
yp = tf.placeholder(dtype=tf.float32, shape=(None, 1))
ww = tf.Variable(np.zeros((2,1)), dtype=tf.float32)
bb = tf.Variable(np.zeros((1,1)), dtype=tf.float32)
ymdl = tf.matmul(xp, ww) + bb
</code></pre>

<pre><code class="language-python">print('Input shape: {}'.format(xp.shape))
print('Ground-truth output shape: {}'.format(yp.shape))
print('Weight shape: {}'.format(ww.shape))
print('Model output shape: {}'.format(ymdl.shape))
</code></pre>

<pre><code>Input shape: (?, 2)
Ground-truth output shape: (?, 1)
Weight shape: (2, 1)
Model output shape: (?, 1)
</code></pre>

<p>The loss function is easily implemented using the method <code>mean_squared_error</code> from <code>losses</code> package.
The optimizer object that actually adjusts the model parameters (TF variables) with the gradient descent algorithm.</p>

<pre><code class="language-python">mdlLoss = tf.losses.mean_squared_error(yp, ymdl)
optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss=mdlLoss)
</code></pre>

<h3 id="4-2-model-training">4.2 Model training</h3>

<p>The next steps are to:
1. initialize the variables.
2. run a new session, which let us perform the actual computation by exploiting the graph structure previously defined.
3. run the optimizer as many steps as the number of epochs <code>Nepoch</code>.
4. run the model with the final parameter set and store the model output <code>ymdl</code> into the prediction array.
5. retrieve the final parameter values by running a dedicated session. A different way would be to call the <a href="https://www.tensorflow.org/api_docs/python/tf/global_variables" target="_blank">global_variables()</a> method and get the variable values by key name.</p>

<pre><code class="language-python">Nepoch = 5000
init = tf.global_variables_initializer()
with tf.Session() as sess:
    sess.run(init)
    Jevol = []
    for kk in range(Nepoch):
        mdl_loss, _ = sess.run([mdlLoss, optimizer], feed_dict={xp: XX1, yp: YY1})
        if kk%100 == 0:
            Jevol.append((kk, mdl_loss))
        if kk==Nepoch-1:
            print('The final model loss is {}'.format(mdl_loss))
    
    Ypred_tf = sess.run(ymdl, feed_dict={xp: XX1})
    bOpt, wOpt = sess.run([bb, ww])
</code></pre>

<pre><code>The final model loss is 0.0608675591647625
</code></pre>

<pre><code class="language-python">Jevol = np.array(Jevol)
plt.figure(figsize=(10, 5))
plt.plot(Jevol[:,0], np.log(Jevol[:,1]), lw=2)
plt.xlabel(&quot;training steps ($N_{epoch}$)&quot;)
plt.ylabel(&quot;Logarithm loss trend ($log(J_{evol})$)&quot;)
plt.title('The model loss over the training epochs')
plt.show()
</code></pre>

<p><img src="output_32_0.png" alt="png" /></p>

<pre><code class="language-python">print('The final RSME is : {}'.format(mean_squared_error(YY1, Ypred_tf)))
print('The final parameter values: {}'.format(np.vstack((bOpt, wOpt))[:,0].tolist()))
</code></pre>

<pre><code>The final RSME is : 0.060867550351984094
The final parameter values: [4.753759384155273, -3.001899242401123, -1.012415885925293]
</code></pre>

<pre><code class="language-python">xx1, xx2, yy = visData1
ypredTF = Ypred_tf.reshape(-1, xx1.shape[-1])
plt.figure(figsize=(10, 5))
ax = plt.axes(projection='3d')
ax.plot_surface(xx1, xx2, ypredTF, rstride=1, cstride=1, cmap='viridis', edgecolor='none', alpha=0.5)
ax.scatter(xx1, xx2, yy, cmap='viridis', linewidth=0.5, alpha=0.5)
ax.set_xlabel('$x_1$')
ax.set_ylabel('$x_2$')
ax.set_zlabel('y')
ax.view_init(20, 30)
plt.tight_layout()
plt.show()
</code></pre>

<p><img src="output_34_0.png" alt="png" /></p>

<h2 id="reference">Reference</h2>

<ol>
<li><a href="http://cs229.stanford.edu/notes/cs229-notes1.pdf" target="_blank">CS229 notes</a></li>
<li><a href="https://www.coursera.org/learn/machine-learning" target="_blank">Machine Learning at Coursera</a></li>
<li><a href="http://people.math.gatech.edu/~ecroot/3225/maximum_likelihood.pdf" target="_blank">Maximum likelihood estimators and least squares</a></li>
<li><a href="https://www-bcf.usc.edu/~gareth/ISL/ISLR%20First%20Printing.pdf" target="_blank">An Introduction to Statistical Learning</a></li>
</ol>

        </div>
        <div class="pgNav PageNavigation col-12 text-center">
          <span>
          <p>&laquo; <a class="" href="/blog/linreg/linreg3/" style="color: #4ABDAC; font-size: 18px; "> Hello world for Machine learning - Part 3</a>
          
          &nbsp;&nbsp; | &nbsp;&nbsp;
          <a class="" href="/blog/linreg/linreg5/" style="color: #4ABDAC; font-size: 18px; ">Hello world for Machine learning - Part 5</a>
          
          &raquo;</p>
          </span>
          
          
        </div>
      </div>
    </div>
  </div>
</section>

    <div class="article-container">
      <script src="https://utteranc.es/client.js"
        repo="takeawildguess/pws"
        issue-term="pathname"
        label="Comment"
        theme="github-dark-orange"
        crossorigin="anonymous"
        async>
</script>

    </div>

    
    

    

    <footer class="pgFoot">
  <div class="container-fluid">
    <div class="row">
      <div class="col-12 text-center icons">
        
        <span>
          <a href="https://github.com/takeawildguess/"><i class="fa fa-github"></i></a><a href="https://twitter.com/takeawildguess4/"><i class="fa fa-twitter"></i></a><a href="https://www.linkedin.com/in/mattia-venditti-9137a124/"><i class="fa fa-linkedin"></i></a>
        </span>
        
      </div>

      <hr style="border: 2px solid #4ABDAC; min-width: 250px; border-radius: 2px; " />
      <div class="col-12 text-center">
        <p>
          &bull; Copyright &copy; 2019, <a href="https://takeawildguess.net/">Mattia Venditti</a> &bull; All rights reserved. &bull;
          <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">
            <img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" />
          </a>
          All blog posts are released under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">
            Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
        </p>
      </div>
      

      <div class="col-6 text-center">
        <p>Disclaimer: The views and opinions on this website are my own and do not reflect or represent the views of my employer.</p>
      </div>
      <div class="col-6 text-center">
        <p>
        Powered by <a href="https://gohugo.io/">Hugo</a> and <a href="https://pages.github.com/">GitHub Pages</a>.
        The favicon and logo were created by myself.
        </p>
      </div>

    </div>
  </div>
</footer>

<a id="back-to-top" href="https://takeawildguess.net/" class="btn btn-primary btn-lg back-to-top" role="button" title="Click to return on the top page"
data-toggle="tooltip" data-placement="left"><i class="fa fa-angle-up"></i></a>


  </body>
</html>
