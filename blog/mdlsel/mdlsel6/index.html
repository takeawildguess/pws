<!DOCTYPE html>
<html lang="en-us">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  

   <meta name="description" content="Personal website"> 
   <meta name="author" content="Your name"> 
  

  <meta name="generator" content="Hugo 0.59.1" />
  <title>Do not overlearn your data too much, learn to generalize - Part 6 &middot; take a wild guess</title>

  
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css"
integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">



 <link rel="stylesheet" href="https://takeawildguess.net/css/main.css"> 


<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway">


 <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/dracula.min.css"> 


<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">


<link rel="stylesheet" href="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.css">

  
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>

<script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script>



    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
     <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/go.min.js"></script>  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/haskell.min.js"></script>  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/kotlin.min.js"></script>  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/scala.min.js"></script>  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/swift.min.js"></script> 
    <script>hljs.initHighlightingOnLoad();</script>






<script>$(document).on('click', function() { $('.collapse').collapse('hide'); })</script>



<script type="text/javascript">
  window.onscroll = function() {myFunction()};
  function myFunction() {
    var winScroll = document.body.scrollTop || document.documentElement.scrollTop;
    var height = document.documentElement.scrollHeight - document.documentElement.clientHeight;
    var scrolled = (winScroll / height) * 100;
    document.getElementById("myBar").style.width = scrolled + "%";
  }
</script>


<script type="text/javascript">
  $(document).ready(function(){
    $(window).scroll(function () {
      if ($(this).scrollTop() > 50) { $('#back-to-top').fadeIn(); } else { $('#back-to-top').fadeOut(); }
    });
    
    $('#back-to-top').click(function () {
      $('#back-to-top').tooltip('hide');
      $('body,html').animate({ scrollTop: 0 }, 800); return false; });
    $('#back-to-top').tooltip('show');
  })
</script>


  
    <link href="//fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href="//fonts.googleapis.com/css?family=Kaushan+Script" rel="stylesheet" type="text/css">
    <link href="//fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic" rel="stylesheet" type="text/css">
    <link href="//fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700" rel="stylesheet" type="text/css">
  

  
    <link rel="shortcut icon" type="image/x-icon" href="https://takeawildguess.net/images/logo/twgLogo.png">
  

  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
  <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
  <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
  <![endif]-->

  
    
    
    
    
    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-151389132-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

    
  

  
  
  







<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']], displayMath: [['$$','$$']],
    processEscapes: true, processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" }, extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }});
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
  MathJax.Hub.Config({
  
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>

  

</head>

  <!-- Navigation -->
<nav class="navbar fixed-top navbar-expand-md navbar-dark bg-dark">
  
    <a class="navbar-brand abs" href="https://takeawildguess.net/">
      <img src="https://takeawildguess.net/images/logo/twgLogo.png" class="img-responsive" id="nav-logo" alt="Do not overlearn your data too much, learn to generalize - Part 6">
    </a>
  
  <a class="navbar-brand" href="/blog/mdlsel/mdlsel6/" style="font-size: 16px; ">Learning to learn your data</a>
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#collapsingNavbar">
      <span class="navbar-toggler-icon"></span>
  </button>
  <div class="navbar-collapse collapse" id="collapsingNavbar">
      <ul class="navbar-nav ml-auto">
        <li class="nav-item"><a class="nav-link" href="https://takeawildguess.net/">Home <span class="sr-only">(current)</span></a></li>
        <li class="nav-item"><a class="nav-link" href="https://takeawildguess.net/blog/">Blog</a></li>
        
        <li class="nav-item dropdown">
          <a class="nav-link dropdown-toggle" href="https://takeawildguess.net/about/" id="navbarDropdown" role="button"
          data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">About</a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
            <a class="dropdown-item" href="https://takeawildguess.net/about/">Main</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://takeawildguess.net/about/#a_twg">TWG</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://takeawildguess.net/about/#a_me">Me</a>
            <a class="dropdown-item" href="https://takeawildguess.net/about/#a_skl">Skills</a>
            <a class="dropdown-item" href="https://takeawildguess.net/about/#a_exp">Experience</a>
            <a class="dropdown-item" href="https://takeawildguess.net/about/#a_pt">Talks</a>
            <div class="dropdown-divider"></div>
            <a class="dropdown-item" href="https://takeawildguess.net/resume/">Resume</a>
          </div>
        </li>

        
      </ul>
      
      <ul class="navbar-nav navbar-right">
        
          <li class="nav-item navbar-icon"><a href="https://github.com/takeawildguess/" target="_blank"><i class="fa fa-github"></i></a></li>
        
          <li class="nav-item navbar-icon"><a href="https://twitter.com/takeawildguess4/" target="_blank"><i class="fa fa-twitter"></i></a></li>
        
          <li class="nav-item navbar-icon"><a href="https://www.linkedin.com/in/mattia-venditti-9137a124/" target="_blank"><i class="fa fa-linkedin"></i></a></li>
        
      </ul>
      
  </div>
  <div class="progress-container">
    <div class="progress-bar" id="myBar"></div>
  </div>
</nav>

  <body data-spy="scroll" data-target="#toc">
    <!-- Hero -->
<header class="postHead">
  <div class="container-fluid overlay">
    <div class="descr">
      <img src="https://takeawildguess.net/blog/images/mdlselHead.jpeg" class="img-fluid" alt="__">
      <div class="card">
        <div class="card-body">
          <h1 class="card-title text-center">Do not overlearn your data too much, learn to generalize - Part 6</h1>
          <h5 class="card-title text-center">Learning to learn your data</h5>
          <h6 class="card-text text-center">May 19, 2019</h6>
          <h6 class="card-text text-center"><span class="fa fa-clock-o"></span> 9 min read</h6>
          <h6 class="card-text text-center">
            <a href="https://takeawildguess.net/tags/model-selection"><kbd class="item-tag">model selection</kbd></a> <a href="https://takeawildguess.net/tags/overfitting"><kbd class="item-tag">overfitting</kbd></a> <a href="https://takeawildguess.net/tags/numpy"><kbd class="item-tag">numpy</kbd></a> <a href="https://takeawildguess.net/tags/regularization"><kbd class="item-tag">regularization</kbd></a> <a href="https://takeawildguess.net/tags/scikit-learn"><kbd class="item-tag">scikit-learn</kbd></a> <a href="https://takeawildguess.net/tags/machine-learning"><kbd class="item-tag">machine learning</kbd></a> <a href="https://takeawildguess.net/tags/learning-curve"><kbd class="item-tag">learning curve</kbd></a> 
          </h6>
        </div>
      </div>
    </div>
  </div>
</header>

    <section class="postContent">
  <div class="container">
    <div class="row">
      
      <div class="col-sm-2 col-lg-2">
        <nav id="toc" data-toggle="toc" class="sticky-top"></nav>
      </div>
      
      <div class="col-lg-10 col-sm-10">
        <div class="container blogPost">
          

<h2 id="1-introduction">1. Introduction</h2>

<p>After two introductory post-series (<a href="/blog/linreg/linreg1/">linear</a> and <a href="/blog/logreg/logreg1/">logistic</a> regression), we dive into a crucial topic that every machine-learning practitioner should be at least aware of: <strong>model selection</strong>.</p>

<p>Basically, we do not want our models to learn our data by heart and then to struggle to handle new unseen data samples.
We want them to be great at generalizing.</p>

<p>We have introduced the <em>bias</em> and <em>variance</em> concepts in <a href="/blog/mdlsel/mdlsel1/">Part1</a> and the bias-variance dilemma, the model capacity, the training/testing split practice and learning curves analysis in <a href="/blog/mdlsel/mdlsel2/">Part2</a>.
We moved to the cross-validation and regularization techniques in <a href="/blog/mdlsel/mdlsel3/">Part3</a>, implemented the Ridge regression in Python in <a href="/blog/mdlsel/mdlsel4/">Part4</a>.</p>

<p>After having shown the effects of the model complexity to a linear binary classification problem in the <a href="/blog/mdlsel/mdlsel5/">previous</a> post, we now go a bit deeper to inspect the model accuracy variability, the application of learning and validation curves with Scikit-learn, selection of the best model capacity with cross-validation with different regularization loss definitions.</p>

<h2 id="2-training-and-testing-accuracy-variability">2. Training and testing accuracy variability</h2>

<p>One key point in the machine-learning field regards how the accuracy of the model might change for varying datasets.
If we sample new data from the same distribution, which comes with noise, is our model accuracy going to change?
If so, to what extent?
This is what the research institute <strong>OpenAI</strong> conceptualize as <em>attacking ML models with adversarial examples</em> in <a href="https://openai.com/blog/adversarial-example-research/" target="_blank">this</a> interesting post.</p>

<p>In this toy case, we sample our dataset <code>Nsim</code> times to correlate the accuracy variability with the noise that changes from one withdraw to the next.
For each sample, we create data with our own function <code>genData</code>, split into training and test sets with <code>train_test_split</code>, scale the training set first with <code>StandardScaler.fit_transform</code> and the test set with <code>.transform</code> to use the same scaling parameters.
We apply logistic regression with no regularization, return the model prediction for both training and test sets&rsquo; inputs, <code>Xtrain</code> and <code>Xtest</code>.
We use the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html" target="_blank">accuracy</a> as metrics and store into two arrays for both sets.
We repeat this process for four different polynomial <code>degrees</code> ranging from 1 to 4.</p>

<pre><code class="language-python">Nsim = 150
accTrainss, accTestss = [], []
degrees = np.arange(1, 5)
for dgr in degrees:
    accTrains, accTests = [], []
    for kk in range(Nsim):
        XX, YY = genData()
        Xtrain, Xtest, Ytrain, Ytest = train_test_split(XX, YY, test_size=0.2, random_state=42)
        scl = StandardScaler()
        Xtrain = scl.fit_transform(polyFeatNoInteraction(Xtrain, dgr))
        Xtest = scl.transform(polyFeatNoInteraction(Xtest, dgr))
        # fit new training data with logistic regression
        lgr = LogisticRegression(C=1e5)
        lgr.fit(Xtrain, Ytrain)
        YpredTR = lgr.predict(Xtrain)
        YpredTS = lgr.predict(Xtest)
        accTrains.append(metrics.accuracy_score(Ytrain, YpredTR))
        accTests.append(metrics.accuracy_score(Ytest, YpredTS))
    accTrainss.append(accTrains)
    accTestss.append(accTests)

accuraciesTrain = np.array(accTrainss)
accuraciesTest = np.array(accTestss)
</code></pre>

<p>We visualize the accuracy variability of each model complexity (degree) with a powerful technique, the <a href="https://en.wikipedia.org/wiki/Box_plot" target="_blank">boxplot</a>, which indicates variability outside the upper and lower quartiles.
A boxplot is a method for graphically depicting groups of numerical data through their quartiles.
What we need now to read this chart is:
1. The horizontal orange line defines the median.
2. The bottom and top sides of the box give the 25th and 75th <a href="https://en.wikipedia.org/wiki/Percentile" target="_blank">percentiles</a>, respectively.
3. The box height gives the <a href="https://en.wikipedia.org/wiki/Interquartile_range" target="_blank">interquartile range</a> (IQR).
4. The two horizontal ticks that confines the vertical line specify the <em>minimum</em> and <em>maximum</em>. The minimum is the difference between the 25th percentile and the $1.5\cdot IQR$.
5. The dots, if any, illustrate the distribution outliers.</p>

<p>You can read <a href="https://towardsdatascience.com/understanding-boxplots-5e2df7bcbd51" target="_blank">this</a> post for further details.</p>

<p>This chart is very useful to go beyond the average accuracy comparison and inspect the actual statistical behaviour of the model.
In this case, we can see how the median accuracy does not change for different degree values and from training to test sets.
Instead, the test accuracy boxes are way more stretched with some outliers reaching levels faraway one to another (92% to 100%).</p>

<pre><code class="language-python">plt.figure(figsize=(10, 5))
plt.subplot(121)
plt.boxplot(accuraciesTrain.T)
plt.xlabel(&quot;X&quot;)
plt.ylabel(&quot;Y&quot;)
plt.ylim([0.9, 1.025])
plt.subplot(122)
plt.boxplot(accuraciesTest.T)
plt.xlabel(&quot;X&quot;)
plt.ylabel(&quot;Y&quot;)
plt.ylim([0.9, 1.025])

plt.show()
</code></pre>

<p><img src="output_5_0.png" alt="png" /></p>

<h2 id="3-learning-curves">3. Learning curves</h2>

<p>We apply the learning-curve analysis to this case.
To make the code much more compact, we exploit two nice features from Scikit-learn: <a href="http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html" target="_blank"><code>make_pipeline</code></a> and <a href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.learning_curve.html" target="_blank"><code>learning_curve</code></a>.</p>

<p>The former method packs a sequence of functionalities into a single <code>model</code> instance. In our case, we stack the polynomial transformation, the scaling and the logistic model.
We then use the latter to train and test the <code>model</code> on a given dataset for increasing samples.
We specify the training set size as a 1D array with the <code>train_sizes</code> attribute. We use here the <em>relative</em> definition, so the <code>train_sizes</code> values range from 10% to 100% of the whole training set.
One of the outputs, <code>trainSizes</code>, stores the actual set sizes.</p>

<pre><code class="language-python">XX, YY = genData()
x1, x2 = XX[:,0], XX[:,1]
model = make_pipeline(PolynomialFeatures(), StandardScaler(), LogisticRegression(C=1e5))
XY = np.c_[XX, YY.reshape(-1, 1)]
np.random.shuffle(XY)
XX, YY = XY[:, :2], XY[:, 2]
trainSizes, trainScores, valScores = learning_curve(model, XX, YY, train_sizes=np.logspace(-1, 0, 20))
</code></pre>

<p>The figure shows the accuracy trend for training and validation sets.
We see the validation trend to keep increasing if more data are used, but the accuracy span is somehow confined.</p>

<pre><code class="language-python">plt.figure()
plt.plot(trainSizes, trainScores.mean(axis=1), label='training')
plt.plot(trainSizes, valScores.mean(axis=1), label='cross-validation')
plt.legend();
</code></pre>

<pre><code>&lt;matplotlib.legend.Legend at 0x1c41d9dbf60&gt;
</code></pre>

<p><img src="output_9_1.png" alt="png" /></p>

<p>We extend this methodology to a third-degree polynomial function.</p>

<pre><code class="language-python">model = make_pipeline(PolynomialFeatures(degree=3), StandardScaler(), LogisticRegression(C=1e5))
trainSizes, trainScores, valScores = learning_curve(model, XX, YY, train_sizes=np.logspace(-1, 0, 20))
</code></pre>

<p>The figure clearly highlights in this case how the training set size helps to narrow down the training/validation accuracy gap, at the expense of a training accuracy drop of 3-4%.</p>

<pre><code class="language-python">plt.figure()
plt.plot(trainSizes, trainScores.mean(axis=1), label='training')
plt.plot(trainSizes, valScores.mean(axis=1), label='cross-validation')
plt.legend();
</code></pre>

<p><img src="output_13_0.png" alt="png" /></p>

<h2 id="4-validation-curves">4. Validation curves</h2>

<p>If the learning curves help us to find the good training set size, the validation curves are useful to select the most suitable hyper-parameter (or set of parameters).
To this end, we use the <code>validation_curve</code> method that runs the <em>piped</em> <code>model</code> for a set of different parameter values, <code>degrees</code>.</p>

<pre><code class="language-python">degrees = np.arange(1, 6)
model = make_pipeline(PolynomialFeatures(), StandardScaler(), LogisticRegression(C=1e5))
# Vary the &quot;degrees&quot; on the pipeline step &quot;polynomialfeatures&quot;
trainScores, valScores = validation_curve(model, XX, YY, param_name='polynomialfeatures__degree', param_range=degrees)
</code></pre>

<p>The plot suggests that a first- or second-degree polynomial function are a good compromise to reduce the error gap.</p>

<pre><code class="language-python"># Plot the mean train score and validation score across folds
plt.figure()
plt.plot(degrees, trainScores.mean(axis=1), label='training')
plt.plot(degrees, valScores.mean(axis=1), label='cross-validation')
plt.legend(loc='best');
</code></pre>

<p><img src="output_17_0.png" alt="png" /></p>

<h2 id="5-regularization-with-cross-validation">5. Regularization with cross-validation</h2>

<p>Rather than finding the best model complexity <code>degree</code> with the validation curves, we could set a very high-dimensional model (<code>degree=6</code>) and seek for the <em>optimal</em> regularization parameter in the logistic regression, <code>C</code>.
For every value in <code>alphas</code>, we create the piped <code>model</code> with the inverse regularization factor <code>C=alpha</code> and estimate the accuracy with a 3-fold (<code>cv=3</code>) cross-validation strategy.</p>

<pre><code class="language-python">alphas = np.logspace(-3, 5, 20)
scores = []
for alpha in alphas:
    model = make_pipeline(PolynomialFeatures(degree=6), StandardScaler(), LogisticRegression(C=alpha))
    scores.append(cross_val_score(model, XX, YY, cv=3).mean())
</code></pre>

<p>The plot suggests that the best <code>alpha</code> value lies around $10^{-1} = 0.1$. A too high regularization factor (low <code>alpha</code>) detriments the accuracy much more severely than a too low, but still a good tradeoff leads to 1% higher validation accuracy and a more robust model.</p>

<pre><code class="language-python">plt.figure()
plt.plot(np.log10(alphas), scores)
</code></pre>

<pre><code>[&lt;matplotlib.lines.Line2D at 0x1eb3a73d668&gt;]
</code></pre>

<p><img src="output_21_1.png" alt="png" /></p>

<h2 id="6-regularization-with-nested-cross-validation">6. Regularization with nested cross-validation</h2>

<p>We now extend this approach to a nested cross-validation analysis that combines the regularization factor and the parameters&rsquo; loss function, with lasso as <code>l1</code> and ridge as <code>l2</code>.
We change the logistic regression solver to <code>liblinear</code> to handle the <code>l1</code> loss function as well.</p>

<pre><code class="language-python">penalties = ['l1', 'l2']
alphas = np.logspace(-3, 5, 20)
scores = []
for penalty in penalties:
    scores_ = []
    for alpha in alphas:
        model = make_pipeline(PolynomialFeatures(degree=6), StandardScaler(),\
                              LogisticRegression(C=alpha, penalty=penalty, solver='liblinear'))
        scores_.append(cross_val_score(model, XX, YY, cv=3).mean())
    scores.append(scores_)
scores = np.array(scores)
</code></pre>

<p>The plot suggests that the best <code>alpha</code> value lies again around $10^-1 = 0.1$ for both loss definitions.
A too high regularization factor (low <code>alpha</code>) detriments the accuracy much more severely than a too low, but still a good tradeoff leads to 1% higher validation accuracy and a more robust model.</p>

<pre><code class="language-python">plt.figure()
plt.plot(np.log10(alphas), scores.T)
plt.legend(['Lasso', 'Ridge'])
plt.ylim([0.7, 1]);
</code></pre>

<p><img src="output_25_0.png" alt="png" /></p>

        </div>
        <div class="pgNav PageNavigation col-12 text-center">
          <span>
          <p>&laquo; <a class="" href="/blog/mdlsel/mdlsel5/" style="color: #4ABDAC; font-size: 18px; "> Do not overlearn your data too much, learn to generalize - Part 5</a>
          
          &nbsp;&nbsp; | &nbsp;&nbsp;
          <a class="" href="/blog/mdlsel/mdlsel7/" style="color: #4ABDAC; font-size: 18px; ">Do not overlearn your data too much, learn to generalize - Part 7</a>
          
          &raquo;</p>
          </span>
          
          
        </div>
      </div>
    </div>
  </div>
</section>

    <div class="article-container">
      <script src="https://utteranc.es/client.js"
        repo="takeawildguess/pws"
        issue-term="pathname"
        label="Comment"
        theme="github-dark-orange"
        crossorigin="anonymous"
        async>
</script>

    </div>

    
    

    

    <footer class="pgFoot">
  <div class="container-fluid">
    <div class="row">
      <div class="col-12 text-center icons">
        
        <span>
          <a href="https://github.com/takeawildguess/"><i class="fa fa-github"></i></a><a href="https://twitter.com/takeawildguess4/"><i class="fa fa-twitter"></i></a><a href="https://www.linkedin.com/in/mattia-venditti-9137a124/"><i class="fa fa-linkedin"></i></a>
        </span>
        
      </div>

      <hr style="border: 2px solid #4ABDAC; min-width: 250px; border-radius: 2px; " />
      <div class="col-12 text-center">
        <p>
          &bull; Copyright &copy; 2019, <a href="https://takeawildguess.net/">Mattia Venditti</a> &bull; All rights reserved. &bull;
          <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">
            <img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" />
          </a>
          All blog posts are released under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">
            Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
        </p>
      </div>
      

      <div class="col-6 text-center">
        <p>Disclaimer: The views and opinions on this website are my own and do not reflect or represent the views of my employer.</p>
      </div>
      <div class="col-6 text-center">
        <p>
        Powered by <a href="https://gohugo.io/">Hugo</a> and <a href="https://pages.github.com/">GitHub Pages</a>.
        The favicon and logo were created by myself.
        </p>
      </div>

    </div>
  </div>
</footer>

<a id="back-to-top" href="https://takeawildguess.net/" class="btn btn-primary btn-lg back-to-top" role="button" title="Click to return on the top page"
data-toggle="tooltip" data-placement="left"><i class="fa fa-angle-up"></i></a>


  </body>
</html>
