<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Scikit Learn on take a wild guess</title>
    <link>https://takeawildguess.net/tags/scikit-learn/</link>
    <description>Recent content in Scikit Learn on take a wild guess</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 24 Mar 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://takeawildguess.net/tags/scikit-learn/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Learning to classify coffee from cappuccino - Part 6</title>
      <link>https://takeawildguess.net/blog/logreg/logreg6/</link>
      <pubDate>Sun, 24 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://takeawildguess.net/blog/logreg/logreg6/</guid>
      <description>1. Introduction and assumptions In this post-series, we are going to study the very basic modelling for classification problems with logistic regression algorithms. Classification entails that the output is a discrete variable taking values on a predefined limited set, where the set dimension is the number of classes. Some examples are spam detection, object recognition and topic identification.
We analyzed the theory in the first post, implement the algorithm with Numpy in Part 2 and using Sklearn and Tensorflow in Part 3.</description>
    </item>
    
    <item>
      <title>Learning to classify coffee from cappuccino - Part 3</title>
      <link>https://takeawildguess.net/blog/logreg/logreg3/</link>
      <pubDate>Sun, 03 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://takeawildguess.net/blog/logreg/logreg3/</guid>
      <description>1. Introduction and assumptions In this post-series, we are going to study the very basic modelling for classification problems, the logistic regression. Classification entails that the output is a discrete variable taking values on a pre-defined limited set, where the set dimension is the number of classes. Some examples are spam detection, object recognition and topic identification.
In this post, we implement the simple logistic regression case that we have analyzed in the first two posts (Part 1 and Part 2) using Sklearn first and Tensorflow then.</description>
    </item>
    
  </channel>
</rss>